steps:
  - name: "gcr.io/cloud-builders/gcloud"
    id: "Trigger new-dataset function to update by triggering the Cloud Build called 'update-new-dataset-cloud-function'"
    entrypoint: bash
    args:
      - "-c"
      - |
        # Install jq
        apt-get -y update && apt-get install -y jq

        # Trigger the Cloud Build to update the new-dataset function
        gcloud builds triggers run update-new-dataset-cloud-function --region=europe-west2 --branch=sdss-712-http-trigger-implementation --substitutions=_SDS_BRANCH=$BRANCH_NAME --format=json | tee /workspace/trigger_response.json
        # Extract the ID of the triggered build
        echo "Writing trigger response to file..."
        _TRIGGER_RESPONSE=$(cat /workspace/trigger_response.json)
        echo "Piping trigger response to jq..."
        _BUILD_ID=$(echo $(cat /workspace/trigger_response.json) | jq -r '.metadata.build.id')
        echo "Triggered build with ID: ${_BUILD_ID}"
        
        # Poll the build status
        while true; do
          _BUILD_STATUS=$(gcloud builds describe $_BUILD_ID --format=json --region=$_REGION)
          _BUILD_STATUS=$(echo ${_BUILD_STATUS} | jq -r '.status')
          echo "Current build status: ${_BUILD_STATUS}"
          if [[ "${_BUILD_STATUS}" == "SUCCESS" ]]; then
            echo "Build succeeded."
            break
          elif [[ "${_BUILD_STATUS}" == "FAILURE" || "${_BUILD_STATUS}" == "CANCELLED" ]]; then
            echo "Build failed or was cancelled."
            exit 1
          else
            echo "Build is still in progress..."
            sleep 15
          fi
        done

  - name: python:3.11
    id: "Upgrade pip"
    entrypoint: "python"
    args: ["-m", "pip", "install", "--upgrade", "pip", "--user"]

  - name: python:3.11
    id: "Install app requirements"
    entrypoint: python
    args: ["-m", "pip", "install", "-r", "requirements.txt", "--user"]

  - name: python:3.11
    id: "Audit packages"
    entrypoint: sh
    args:
      - "-c"
      - |
        make audit

  - name: python:3.11
    id: "Check linting and code formatting"
    entrypoint: sh
    args:
      - "-c"
      - |
        make lint

  - name: python:3.11
    id: "Run unit tests"
    entrypoint: sh
    args:
      - "-c"
      - |
        make setup
        make unit-test

  - name: docker
    id: "docker build and push"
    entrypoint: sh
    args:
      - "-c"
      - |
        docker build -t "europe-west2-docker.pkg.dev/${PROJECT_ID}/sds/sds:${SHORT_SHA}" -t "europe-west2-docker.pkg.dev/${PROJECT_ID}/sds/sds:latest" .
        docker push "europe-west2-docker.pkg.dev/${PROJECT_ID}/sds/sds:${SHORT_SHA}"
        docker push "europe-west2-docker.pkg.dev/${PROJECT_ID}/sds/sds:latest"

  

  - name: "gcr.io/cloud-builders/gcloud"
    id: "Show image vulnerabilities (ons-sds-dev only)"
    entrypoint: bash
    args:
      - "-c"
      - |
        if [ ${PROJECT_ID} == "ons-sds-dev" ]
        then
          gcloud artifacts vulnerabilities list europe-west2-docker.pkg.dev/${PROJECT_ID}/sds/sds:latest \
            --format=json > /workspace/vulnerability_report
        else
          echo "Step not run for ${PROJECT_ID}"
        fi

  - name: "gcr.io/cloud-builders/gcloud"
    id: "Check for critical vulnerabilities (ons-sds-dev only)"
    entrypoint: bash
    args:
      - "-c"
      - |
        if [ ${PROJECT_ID} == "ons-sds-dev" ]
        then
          apt-get -y update && apt-get install -y jq
          if jq -e '.[] | select( .vulnerability.effectiveSeverity == "CRITICAL")' /workspace/vulnerability_report > /dev/null; then
            echo "Error: Critical vulnerability found with image"
            exit 1
          fi
        else
          echo "Step not run for ${PROJECT_ID}"
        fi

  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: "Run container"
    entrypoint: gcloud
    args:
      [
        "run",
        "deploy",
        "sds",
        "--image",
        "europe-west2-docker.pkg.dev/${PROJECT_ID}/sds/sds:${SHORT_SHA}",
        "--region",
        "europe-west2",
        "--allow-unauthenticated",
        "--ingress",
        "internal-and-cloud-load-balancing",
        "--update-env-vars",
        "SDS_APPLICATION_VERSION=development",
        "--cpu-boost",
        "--session-affinity",
        "--min-instances",
        "1",
        "--max-instances",
        "2",
      ]

  - name: "gcr.io/cloud-builders/gcloud"
    id: "Retrieve `OAUTH_BRAND_NAME` and save it to workspace"
    entrypoint: sh
    args:
      - "-c"
      - |
        gcloud iap oauth-brands list --format='value(name)' --limit=1 --project=${PROJECT_ID} \
        > /workspace/oauth_brand_name

  - name: "gcr.io/cloud-builders/gcloud"
    id: "Retrieve `OAUTH_CLIENT_NAME` and save it to workspace"
    entrypoint: sh
    args:
      - "-c"
      - |
        gcloud iap oauth-clients list $(cat /workspace/oauth_brand_name) --format='value(name)' \
        --limit=1 \
        > /workspace/oauth_client_name
 
  - name: python:3.11
    id: "Run integration test"
    entrypoint: sh
    args:
      - "-c"
      - |
        export INT_DATASET_BUCKET_NAME=${_DATASET_BUCKET_NAME}
        export INT_AUTODELETE_DATASET_BUCKET_FILE=${_AUTODELETE_DATASET_BUCKET_FILE}
        export INT_RETAIN_DATASET_FIRESTORE=${_RETAIN_DATASET_FIRESTORE}
        export INT_LOG_LEVEL=${_LOG_LEVEL}
        export INT_PROJECT_ID=${PROJECT_ID}
        export INT_SCHEMA_BUCKET_NAME=${_SCHEMA_BUCKET_NAME}
        export INT_PUBLISH_SCHEMA_TOPIC_ID=${_PUBLISH_SCHEMA_TOPIC_ID}
        export INT_PUBLISH_DATASET_TOPIC_ID=${_PUBLISH_DATASET_TOPIC_ID}
        export INT_PUBLISH_DATASET_ERROR_TOPIC_ID=${_PUBLISH_DATASET_ERROR_TOPIC_ID}
        export INT_API_URL=${_API_URL}
        OAUTH_CLIENT_NAME=$(cat /workspace/oauth_client_name)
        export INT_OAUTH_CLIENT_ID=${OAUTH_CLIENT_NAME##*/}
        export INT_SURVEY_MAP_URL=${_SURVEY_MAP_URL}
        export INT_FIRESTORE_DB_NAME=${_FIRESTORE_DB_NAME}
        make integration-test-cloudbuild

options:
  logging: CLOUD_LOGGING_ONLY
