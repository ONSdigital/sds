steps:
  - name: python
    id: "Setup Python"
    entrypoint: pip
    args: [ "install", "-r", "requirements.txt" , "--user"]
  - name: python
    id: "black"
    entrypoint: python
    args: ["-m", "black", "src", "devtools", "--check"]
  - name: python
    id: "isort"
    entrypoint: python
    args: ["-m", "isort", "src", "devtools", "--check-only",  "--profile", "black"]
  - name: python
    id: "flake8"
    entrypoint: python
    args: ["-m", "flake8", "src", "devtools", "--max-line-length=127"]
  - name: python
    id: "unit tests"
    entrypoint: sh
    args:
      - '-c'
      - |
        make setup 
        make unit-test
  - name: python
    id: 'Audit packages'
    entrypoint: sh
    args:
      - '-c'
      - |
        make audit
  - name: docker
    id: build_and_push
    entrypoint: sh
    args:
      - '-c'
      - |
        docker build -t "europe-west2-docker.pkg.dev/${_PROJECT_ID}/sds/sds:$SHORT_SHA" -t "europe-west2-docker.pkg.dev/${_PROJECT_ID}/sds/sds:latest" .
        docker push "europe-west2-docker.pkg.dev/${_PROJECT_ID}/sds/sds:$SHORT_SHA"
        docker push "europe-west2-docker.pkg.dev/${_PROJECT_ID}/sds/sds:latest"
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: "Run image"
    entrypoint: gcloud
    args: [ 'run', 'deploy', 'sds', '--image', 'europe-west2-docker.pkg.dev/${_PROJECT_ID}/sds/sds:$SHORT_SHA',
            '--region', 'europe-west2' ]
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: "Deploy cloud function"
    entrypoint: sh
    args:
      - '-c'
      - |
        cd src/app/
        gcloud functions deploy new-dataset-function \
        --gen2 \
        --runtime=python311 \
        --region=europe-west2 \
        --source=. \
        --entry-point=new_dataset \
        --trigger-event-filters="type=google.cloud.storage.object.v1.finalized" \
        --trigger-event-filters="bucket=${_DATASET_BUCKET_NAME}" \
        --set-env-vars="DATASET_BUCKET_NAME=${_DATASET_BUCKET_NAME},SCHEMA_BUCKET_NAME=${_SCHEMA_BUCKET_NAME},CONF=cloud-build,AUTODELETE_DATASET_BUCKET_FILE=${_AUTODELETE_DATASET_BUCKET_FILE},LOG_LEVEL=${_LOG_LEVEL},PROJECT_ID=${_PROJECT_ID}"
  - name: 'gcr.io/cloud-builders/gcloud'
    id: "Get token"
    entrypoint: sh
    args:
      - '-c'
      - |
        gcloud auth print-identity-token --impersonate-service-account=${_CLOUDBUILD_SA} > /workspace/token
        curl -H "Authorization: Bearer $(cat /workspace/token)" ${_API_URL}/docs
  - name: python
    id: "Run integration test"
    entrypoint: sh
    args:
      - '-c'
      - |
        export ACCESS_TOKEN=$(cat /workspace/token)
        export INT_API_URL=$_API_URL
        export INT_DATASET_BUCKET_NAME=$_DATASET_BUCKET_NAME
        export INT_AUTODELETE_DATASET_BUCKET_FILE=$_AUTODELETE_DATASET_BUCKET_FILE
        export INT_LOG_LEVEL=$_LOG_LEVEL
        export INT_PROJECT_ID=$_PROJECT_ID
        export INT_SCHEMA_BUCKET_NAME=$_SCHEMA_BUCKET_NAME
        make integration-test-cloudbuild
options:
  logging: CLOUD_LOGGING_ONLY
